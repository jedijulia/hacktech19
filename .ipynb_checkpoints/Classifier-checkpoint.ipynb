{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outline:\n",
    "- load datasets\n",
    "- count vectorize training data\n",
    "- fit\n",
    "- predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def preprocess(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = stopwords.words('english')\n",
    "    words = [lemmatizer.lemmatize(word.lower()) for word in word_tokenize(text)]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# good data\n",
    "with open('data/good.csv', 'r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    line_count = 0\n",
    "    train_data = []\n",
    "    train_classif = []\n",
    "    fields = ['Name']\n",
    "    # combine text from fields\n",
    "    for row in csv_reader:\n",
    "        text = ''\n",
    "        for field in fields:\n",
    "            # TODO: preprocessing\n",
    "            text += row[field]\n",
    "        train_data.append(preprocess(text.decode('utf8')))\n",
    "        train_classif.append(1) #hardcoded\n",
    "\n",
    "# bad data\n",
    "    train_data.append('Clear Plastic Tote Bag Women Transparent PVC Handbag Zip Purse Stadium Security')\n",
    "    train_classif.append(0)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "\n",
    "# with open('data/good.csv', 'r') as csv_file:\n",
    "#     train_data = [{k: int(v) for k, v in row.items()} for row in csv.DictReader(csv_file)]\n",
    "# print train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 141)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count vectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "train_counts = count_vect.fit_transform(train_data)\n",
    "train_counts.shape\n",
    "\n",
    "# TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(train_counts)\n",
    "train_tf = tf_transformer.transform(train_counts)\n",
    "train_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression().fit(train_tf, train_classif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['plastic transparent pvc asdfoijasdf']\n",
    "new_counts = count_vect.transform(docs_new)\n",
    "new_tfidf = tf_transformer.transform(new_counts)\n",
    "\n",
    "predicted = classifier.predict(new_tfidf)\n",
    "\n",
    "print predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['alt.atheism', 'soc.religion.christian',\n",
    "              'comp.graphics', 'sci.med']\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train',\n",
    "    categories=categories, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "Organization: The City University\n",
      "Lines: 14\n",
      "\n",
      "Does anyone know of a good way (standard PC application/PD utility) to\n",
      "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
      "do the same, converting to HPGL (HP plotter) files.\n",
      "\n",
      "Please email any response.\n",
      "\n",
      "Is this the correct group?\n",
      "\n",
      "Thanks in advance.  Michael.\n",
      "-- \n",
      "Michael Collier (Programmer)                 The Computer Unit,\n",
      "Email: M.P.Collier@uk.ac.city                The City University,\n",
      "Tel: 071 477-8000 x3769                      London,\n",
      "Fax: 071 477-8565                            EC1V 0HB.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train.data)\n",
    "print twenty_train.data[0]\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
